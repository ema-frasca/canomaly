{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#notebook { padding-top:0px; } .container { width:100%; } .end_space { min-height:0px; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ast import literal_eval\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from IPython.core.display import display, HTML\n",
    "from numpy import nan\n",
    "display(HTML(\"<style>\"\n",
    "    + \"#notebook { padding-top:0px; } \" \"\"\n",
    "    + \".container { width:100%; } \"\n",
    "    + \".end_space { min-height:0px; } \"\n",
    "    + \"</style>\"))\n",
    "# import colors\n",
    "\n",
    "\n",
    "def highlight_max(sett):\n",
    "    if sett.dtype == 'O':\n",
    "        s = sett.str.split(' ').apply(lambda x: float(x[0]) if x[0] != '-' else np.nan)\n",
    "    else:\n",
    "        s = sett\n",
    "    is_max = s == s.max()\n",
    "    \n",
    "    return ['font-weight: bold' if v else '' for v in is_max]\n",
    "\n",
    "def highlight_group(sett):\n",
    "    try:\n",
    "        if sett.dtype == 'O':\n",
    "            oboe = sett.str.split(' ').apply(lambda x: float(x[0]) if x[0] != '-' else np.nan)\n",
    "        else:\n",
    "            oboe = sett\n",
    "        is_max = oboe.to_frame().apply(lambda x: oboe[oboe.index.get_level_values(0) == x.name[0]].max() == x.item(), axis=1)\n",
    "        return ['font-weight: bold' if v else '' for v in is_max]\n",
    "    except:\n",
    "        return ['' for _ in sett]\n",
    "\n",
    "def highlight_group_min(sett):\n",
    "    try:\n",
    "        if sett.dtype == 'O':\n",
    "            oboe = sett.str.split(' ').apply(lambda x: float(x[0]) if x[0] != '-' else np.nan)\n",
    "        else:\n",
    "            oboe = sett\n",
    "        is_max = oboe.to_frame().apply(lambda x: oboe[oboe.index.get_level_values(0) == x.name[0]].min() == x.item(), axis=1)\n",
    "        return ['font-weight: bold' if v else '' for v in is_max]\n",
    "    except:\n",
    "        return ['' for _ in sett]\n",
    "\n",
    "    \n",
    "def highlight_min(sett):\n",
    "    if sett.dtype == 'O':\n",
    "        s = sett.str.split(' ').apply(lambda x: float(x[0]) if x[0] != '-' else np.nan)\n",
    "    else:\n",
    "        s = sett\n",
    "    is_max = s == s.min()\n",
    "    \n",
    "    return ['font-weight: bold' if v else '' for v in is_max]\n",
    "\n",
    "def b_g(sett, cmap='PuBu', low=0, high=0):\n",
    "    if sett.dtype == 'O':\n",
    "        s = sett.str.split(' ').apply(lambda x: float(x[0]) if x[0] != '-' else np.nan)\n",
    "    else:\n",
    "        s = sett\n",
    "    a = s\n",
    "    rng = a.max() - a.min()\n",
    "    norm = colors.Normalize(a.min() - (rng * low),\n",
    "                        a.max() + (rng * high))\n",
    "    normed = norm(a.values)\n",
    "    c = [colors.rgb2hex(x) for x in plt.cm.get_cmap(cmap)(normed)]\n",
    "    return ['background-color: %s' % color for color in c]\n",
    "\n",
    "def method_to_df(apath, setting, dataset, method):\n",
    "    last = ' '.join([setting, dataset, method])\n",
    "    with open(apath + '%s/%s/' % (setting, dataset) + method +'/logs.pyd', 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "    o = pd.DataFrame.from_records([eval(x.replace('nan', 'float(\\'nan\\')')) for x in lines])\n",
    "    \n",
    "    o = o.rename(columns={'cs_size':'buffer_size'})\n",
    "    if 'buffer_size' not in o:\n",
    "        o['buffer_size'] = 0\n",
    "    if 'job_number' in o.columns:\n",
    "        del o['job_number']\n",
    "    o['method'] = method\n",
    "    return o\n",
    "\n",
    "\n",
    "req_rep = 1\n",
    "print_args= False\n",
    "display_pre = False\n",
    "howmany_pre = 1\n",
    "print_other_metrics = False\n",
    "t_distinct_cols = ['buffer_size', 'method', 'shap_weight', 'shap_all', 'n_epochs']\n",
    "ignore_cols = []\n",
    "excluded_methods = []\n",
    "included_methods = []\n",
    "excluded_datasets = []\n",
    "\n",
    "sec_respath = None\n",
    "\n",
    "# PAMI\n",
    "respath = '../storage/results/dataset-can-mnist/classes_per_task-1/logs.pyd'#'C:\\\\Users\\\\emace\\\\AImageLab\\\\SRV-Continual\\\\results\\\\mammoth\\\\results\\\\'\n",
    "sec_respath = None #'/home/mbosc/srv-nas/mammoth-master/results/'\n",
    "third_respath = None #'/home/mbosc/phd/pami/results_buzz/'\n",
    "\n",
    "respaths = [respath, sec_respath, third_respath]\n",
    "islist = lambda col: any([type(x) == list for x in col.values])\n",
    "\n",
    "def aggf(x):\n",
    "#     if len(x) > 2:\n",
    "#         return x.sort_values()[1:-1].mean()\n",
    "#     else:\n",
    "        return x.mean()\n",
    "\n",
    "# -------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import file\n",
    "with open(os.path.join(respath), 'r') as obj:\n",
    "    file = obj.readlines()\n",
    "file_parsed = map(eval, file)\n",
    "df_file = pd.DataFrame(list(file_parsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>logs</th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>optim</th>\n",
       "      <th>lr</th>\n",
       "      <th>joint</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>latent_space</th>\n",
       "      <th>sparse_weight</th>\n",
       "      <th>norm_order</th>\n",
       "      <th>classes_per_task</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>auc_final</th>\n",
       "      <th>auc_average</th>\n",
       "      <th>auc_per_task</th>\n",
       "      <th>conf_matrix_per_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3588477890</td>\n",
       "      <td>False</td>\n",
       "      <td>can-mnist</td>\n",
       "      <td>sae</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22da4cf3-85b1-47c2-96eb-90da14df1274</td>\n",
       "      <td>2022-01-28 18:13:11.536771</td>\n",
       "      <td>0.505262</td>\n",
       "      <td>0.549148</td>\n",
       "      <td>{'0': {'[0]': 0.8114526675415593, '[1]': nan, ...</td>\n",
       "      <td>{0: {'0[0]': 76.50629796008674, '1[1]': 147.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1939617363</td>\n",
       "      <td>False</td>\n",
       "      <td>can-mnist</td>\n",
       "      <td>sae</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44a40b10-0528-4ae3-bf89-d8e6b8a3309f</td>\n",
       "      <td>2022-01-28 18:15:21.385007</td>\n",
       "      <td>0.395129</td>\n",
       "      <td>0.504338</td>\n",
       "      <td>{'0': {'[0]': 0.5473158853342505, '[1]': nan, ...</td>\n",
       "      <td>{0: {'0[0]': 87.49594212356878, '1[1]': 162.67...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1225029300</td>\n",
       "      <td>False</td>\n",
       "      <td>can-mnist</td>\n",
       "      <td>sae</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>b972705f-362b-48ba-9cac-cc8476432218</td>\n",
       "      <td>2022-01-28 18:29:27.464874</td>\n",
       "      <td>0.444863</td>\n",
       "      <td>0.537492</td>\n",
       "      <td>{'0': {'[0]': 0.5584516833341762, '[1]': nan, ...</td>\n",
       "      <td>{0: {'0[0]': 136.12866878120266, '1[1]': 143.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         seed   logs    dataset model optim   lr  joint  batch_size  n_epochs  latent_space  sparse_weight  norm_order  classes_per_task                                    id                   timestamp  auc_final  auc_average                                       auc_per_task                               conf_matrix_per_task\n",
       "0  3588477890  False  can-mnist   sae   sgd  0.1  False          16         2            32            1.0           1                 1  22da4cf3-85b1-47c2-96eb-90da14df1274  2022-01-28 18:13:11.536771   0.505262     0.549148  {'0': {'[0]': 0.8114526675415593, '[1]': nan, ...  {0: {'0[0]': 76.50629796008674, '1[1]': 147.41...\n",
       "1  1939617363  False  can-mnist   sae   sgd  0.1  False          16         2            32            1.0           1                 1  44a40b10-0528-4ae3-bf89-d8e6b8a3309f  2022-01-28 18:15:21.385007   0.395129     0.504338  {'0': {'[0]': 0.5473158853342505, '[1]': nan, ...  {0: {'0[0]': 87.49594212356878, '1[1]': 162.67...\n",
       "2  1225029300  False  can-mnist   sae   sgd  0.1  False          16         2            32            1.0           1                 1  b972705f-362b-48ba-9cac-cc8476432218  2022-01-28 18:29:27.464874   0.444863     0.537492  {'0': {'[0]': 0.5584516833341762, '[1]': nan, ...  {0: {'0[0]': 136.12866878120266, '1[1]': 143.8..."
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_auc = pd.concat([pd.DataFrame.from_dict(sing[1].loc[0,'auc_per_task'], orient='index')]*2)\n",
    "total_auc.reset_index().groupby('index').mean()\n",
    "\n",
    "def calc_mean_on_matrix(X):\n",
    "    total_df = pd.concat([pd.DataFrame.from_dict(x, orient='index') for x in X])\n",
    "    return total_df.reset_index().groupby('index').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_pm_std(x):\n",
    "    return f'{x.mean().round(3)}+-{x.std().round(3)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting links to html tags\n",
    "def path_to_image_html(path):\n",
    "    return '<img src=\"'+ path + '\" width=\"60\" >'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_final</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc_average</th>\n",
       "      <th>auc_per_task</th>\n",
       "      <th>conf_matrix_per_task</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>calc_mean_pm_std</th>\n",
       "      <th>len</th>\n",
       "      <th>calc_mean_pm_std</th>\n",
       "      <th>len</th>\n",
       "      <th>calc_mean_on_matrix</th>\n",
       "      <th>calc_mean_on_matrix</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>optim</th>\n",
       "      <th>lr</th>\n",
       "      <th>joint</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>latent_space</th>\n",
       "      <th>classes_per_task</th>\n",
       "      <th>sparse_weight</th>\n",
       "      <th>norm_order</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>can-mnist</th>\n",
       "      <th>sae</th>\n",
       "      <th>sgd</th>\n",
       "      <th>0.1</th>\n",
       "      <th>False</th>\n",
       "      <th>16</th>\n",
       "      <th>2</th>\n",
       "      <th>32</th>\n",
       "      <th>1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.448+-0.055</td>\n",
       "      <td>3</td>\n",
       "      <td>0.53+-0.023</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.6390734120699954, nan, nan, nan, nan, nan,...</td>\n",
       "      <td>[[100.04363628828605, 151.3144173472917, 195.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  auc_final          auc_average                                           auc_per_task                               conf_matrix_per_task\n",
       "                                                                                                           calc_mean_pm_std len calc_mean_pm_std len                                calc_mean_on_matrix                                calc_mean_on_matrix\n",
       "dataset   model optim lr  joint batch_size n_epochs latent_space classes_per_task sparse_weight norm_order                                                                                                                                                \n",
       "can-mnist sae   sgd   0.1 False 16         2        32           1                1.0           1              0.448+-0.055   3      0.53+-0.023   3  [[0.6390734120699954, nan, nan, nan, nan, nan,...  [[100.04363628828605, 151.3144173472917, 195.6..."
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_elab = df_file.copy()\n",
    "\n",
    "common_keys=['dataset','model','optim','lr','joint','batch_size','n_epochs','latent_space','classes_per_task']\n",
    "part_keys = {'sae':['sparse_weight','norm_order']}\n",
    "elaboration_cols = {\n",
    "    'auc_final':[calc_mean_pm_std, len],\n",
    "    'auc_average':[calc_mean_pm_std, len],\n",
    "    'auc_per_task': [calc_mean_on_matrix],\n",
    "    'conf_matrix_per_task': [calc_mean_on_matrix]\n",
    "    \n",
    "}\n",
    "task_per_task_elaboration_cols = {\n",
    "    \n",
    "}\n",
    "total_list = []\n",
    "for model, df_model in df_elab.groupby('model'):\n",
    "    df_model['model'] = model\n",
    "    total_keys = common_keys+part_keys[model]\n",
    "    \n",
    "    df_single = df_model.groupby(total_keys).agg(elaboration_cols)\n",
    "        \n",
    "    total_list.append(df_single)\n",
    "\n",
    "pd.concat(total_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "display(HTML('''<script>function copyURI(t,e){t.preventDefault(),navigator.clipboard.writeText(e)}</script>'''))\n",
    "# for setting in ['task-il', 'class-il']:\n",
    "#     if not os.path.isdir(respath + setting): continue\n",
    "\n",
    "for dataset in [x for x in set(os.listdir(respath + setting) + (os.listdir(sec_respath + setting) if sec_respath else [])) if x not in excluded_datasets]:\n",
    "\n",
    "    print(dataset, '-', setting)\n",
    "\n",
    "    # -------------------------- READ LOG FILES INTO A SINGLE DATAFRAME ----------------------------\n",
    "    methods = None\n",
    "    for apath in [x for x in respaths if x is not None]:\n",
    "        if dataset in excluded_datasets: continue\n",
    "\n",
    "        if not os.path.isdir(apath + '%s/%s/' % (setting, dataset)): continue;\n",
    "\n",
    "        for method in os.listdir(apath + '%s/%s/' % (setting, dataset)):\n",
    "            if method.startswith('__'): continue;\n",
    "            if method in excluded_methods: continue;\n",
    "            if len(included_methods) > 0 and method not in included_methods: continue;\n",
    "            if not os.path.isfile(apath + '%s/%s/' % (setting, dataset) + method +'/logs.pyd'): continue;\n",
    "            try:\n",
    "                o = method_to_df(apath, setting, dataset, method)\n",
    "                for col in ignore_cols:\n",
    "                    if col in o.columns:\n",
    "                        o = o.drop([col], 1)\n",
    "                if methods is None:\n",
    "                    methods = o.copy()\n",
    "                else:\n",
    "                    methods = pd.concat([methods,o], axis=0, ignore_index=True, sort=False)\n",
    "            except (pd.errors.ParserError, ValueError):\n",
    "                print('Could not parse', apath, setting, dataset, method)\n",
    "    if methods is None:\n",
    "        continue\n",
    "    print('%d methods found' % len(methods))\n",
    "    methods.fillna('', inplace=True)\n",
    "    methods['conf_timestamp'] = pd.to_datetime(methods['conf_timestamp'])\n",
    "    methods = methods[~methods['method'].isin(excluded_methods)]\n",
    "    for c in methods.columns:\n",
    "        if islist(methods[c]):\n",
    "            methods[c] = methods[c].apply(str)\n",
    "\n",
    "    methods_map_time = methods.conf_timestamp > '1980'\n",
    "    # methods_map_time = methods.conf_timestamp > '2021-11-03 15:00:00'\n",
    "    if methods_map_time.sum() < 1:\n",
    "        continue\n",
    "\n",
    "    # -------------------------- DISTINGUISH COLUMNS ----------------------------\n",
    "    config_columns = [x for x in methods.columns if x.startswith('conf_')] +\\\n",
    "        ['seed', 'notes', 'csv_log', 'loss_log', 'examples_log', 'examples_full_log', 'tensorboard', 'savecheck', 'validation', 'dataset', 'ignore_other_metrics', 'balancoir', 'debug_mode','non_verbose',\n",
    "        'distributed', 'start_from', 'intensive_savecheck', 'stopafter', 'loadcheck', 'autorelaunch', 'force_compat']\n",
    "    config_columns = [x for x in config_columns if x in methods.columns]\n",
    "\n",
    "    metric_columns = [x for x in methods.columns if any(map(lambda y: x.startswith(y), \\\n",
    "                        ['accuracy_', 'accmean_', 'forward_transfer', 'backward_transfer', 'forgetting']))]\n",
    "    end = [x for x in methods.columns if x.startswith('accmean_')][-1]\n",
    "\n",
    "    methods['aic'] = methods[[x for x in methods.columns if x.startswith('accmean_')]].mean(1)\n",
    "    metric_columns.append('aic')\n",
    "\n",
    "    parameter_columns = [x for x in methods.columns if x not in config_columns and x not in metric_columns]\n",
    "\n",
    "    for c in metric_columns:\n",
    "        methods[c] = pd.to_numeric(methods[c])\n",
    "    distinct_cols = [x for x in t_distinct_cols if x in methods.columns]\n",
    "\n",
    "    # -------------------------- GROUP BY PARAMETERS ----------------------------\n",
    "    agg_dict = {end: ['count', aggf, 'std']}\n",
    "    if len(metric_columns):\n",
    "        agg_dict.update({x: ['count', aggf, 'std'] for x in metric_columns})\n",
    "    agg_dict.update({'conf_jobnum': lambda x: str(list(x.values))})\n",
    "\n",
    "    trez = methods[methods_map_time].groupby(parameter_columns).agg(agg_dict)\n",
    "    trez.columns = ['%s-%s' % (a, b) for a,b in list(trez.columns)]\n",
    "    trez = trez.reset_index().sort_values(by='%s-%s' % (end, 'aggf'), ascending=False)\n",
    "\n",
    "    # -------------------------- PREPARE OUTPUT ----------------------------\n",
    "    tmpout = trez[trez['%s-%s' %(end, 'count')] >= req_rep]\n",
    "\n",
    "    tmpout['outmetric'] = pd.Series(['0'] * len(tmpout), index=tmpout.index).str.repeat((tmpout['%s-%s' %(end, 'aggf')] < 10).astype(int).values) + tmpout['%s-%s' %(end, 'aggf')].apply(lambda x: '%.2f' % x) + ' Â± ' + tmpout['%s-%s' %(end, 'std')].apply(lambda x: '%.2f' % x)\n",
    "    tmpout = tmpout.sort_values(by='outmetric', ascending=False)\n",
    "    tmpout = tmpout.groupby(distinct_cols + ['conf_jobnum-<lambda>']).head(1)\n",
    "\n",
    "\n",
    "    for m in [end] + (metric_columns if print_other_metrics else []):\n",
    "        print('--- %s ---' % m)\n",
    "        met1 = tmpout['%s-%s' %(m, 'aggf')].apply(lambda x: '%05.2f' % x)\n",
    "        met2 = ' Â± ' + tmpout['%s-%s' %(m, 'std')].apply(lambda x: '%.2f' % x)\n",
    "        met3 = \" [\" + tmpout['%s-%s' %(m, 'count')].apply(lambda x: '%d' % x) + tmpout['conf_jobnum-<lambda>'].apply(lambda x: '] <a onclick=\"copyURI(event, \\'%s\\')\">ðŸ“‹</a>' % str(x).replace('\\'', '\\\\\\''))\n",
    "        met4 = ' (FG ' + tmpout['%s-%s' %('forgetting', 'aggf')].apply(lambda x: '%05.2f' % x) + ')'\n",
    "        tmpout['tmpmetric'] = met1  + met2 + met3 + met4\n",
    "        out = tmpout.groupby(distinct_cols)['tmpmetric'].max().unstack(-1).fillna('-')\n",
    "\n",
    "        is_max = np.equal(out.values, out.max(axis=1).values[None].T).tolist()\n",
    "\n",
    "\n",
    "        if len(out) > 0:\n",
    "            display(out.style.apply(highlight_max if m != 'forgetting' else highlight_min, axis=0))\n",
    "                \n",
    "        \n",
    "    \n",
    "            \n",
    "\n",
    "    \n",
    "        print('\\n\\n', '-' * 30, '\\n\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def series_to_args(ser):\n",
    "    global parameter_columns\n",
    "    if len(ser) == 1:\n",
    "        ser = ser.replace('', np.nan)[parameter_columns].dropna(1, 'all').iloc[0]\n",
    "    s = ser.to_dict()\n",
    "    del s['method']\n",
    "    bits = []\n",
    "    for x, y in s.items():\n",
    "        if type(y) != float or np.isnan(y):\n",
    "            if type(y) == str and y[0] == '[' and y[-1] == ']':\n",
    "                bits.append(f'--{x} {y[1:-1].replace(\",\", \" \")}')\n",
    "            else:\n",
    "                bits.append(f'--{x}={(str(y) if not str(y).endswith(\".0\") else str(y)[:-2])}')\n",
    "\n",
    "                \n",
    "    return ' '.join(bits)\n",
    "    \n",
    "def gridmap(methods, jobs1, jobs2=None, titles=None, delta=False):\n",
    "    job1l = []\n",
    "    \n",
    "    ntasks = sorted([int(x.split('task')[-1]) for x in methods.columns if x.startswith('accmean_task')])[-1]\n",
    "    fsize=(ntasks*0.6, ntasks*0.6)\n",
    "\n",
    "    for job in jobs1:\n",
    "        arrayv = []\n",
    "        mydata = methods[methods.conf_jobnum == job][[x for x in metric_columns if 'accuracy_' in x]].iloc[0]\n",
    "        for i in range(1, ntasks+1):\n",
    "            arrayv.append([])\n",
    "            for j in range(1, i+1):\n",
    "                arrayv[-1].append(mydata[f'accuracy_{j}_task{i}'] - (0 if not delta else 100 / i))\n",
    "            avg = np.mean(arrayv[-1])\n",
    "            for j in range(ntasks-i):\n",
    "                arrayv[-1].append(np.nan)\n",
    "            arrayv[-1].append(avg)\n",
    "        job1l.append(np.array(arrayv))\n",
    "    plt.figure(figsize=fsize)\n",
    "    sns.heatmap(np.stack(job1l).mean(0), annot=True, fmt='.1f')\n",
    "    if titles is not None:\n",
    "        plt.title(titles[0])\n",
    "    else:\n",
    "        plt.title(methods[methods.conf_jobnum ==job].method.iloc[0])\n",
    "    \n",
    "    if jobs2 is not None:\n",
    "        job2l = []\n",
    "        for job in jobs2:\n",
    "            arrayv = []\n",
    "            mydata = methods[methods.conf_jobnum == job][[x for x in metric_columns if 'accuracy_' in x]].iloc[0]\n",
    "            for i in range(1, ntasks+1):\n",
    "                arrayv.append([])\n",
    "                for j in range(1, i+1):\n",
    "                    arrayv[-1].append(mydata[f'accuracy_{j}_task{i}'] - (0 if not delta else 100 / i))\n",
    "                avg = np.mean(arrayv[-1])\n",
    "                for j in range(ntasks-i):\n",
    "                    arrayv[-1].append(np.nan)\n",
    "                arrayv[-1].append(avg)\n",
    "            job2l.append(np.array(arrayv))\n",
    "        plt.figure(figsize=fsize)\n",
    "        sns.heatmap(np.stack(job2l).mean(0), annot=True, fmt='.1f')\n",
    "        if titles is not None:\n",
    "            plt.title(titles[1])\n",
    "        else:\n",
    "            plt.title(methods[methods.conf_jobnum ==job].method.iloc[0])\n",
    "        \n",
    "        conf = np.stack(job1l).mean(0) - np.stack(job2l).mean(0)\n",
    "        \n",
    "        plt.figure(figsize=fsize)\n",
    "        sns.heatmap(conf, annot=True, cmap='bwr', vmin=-np.nanmax(abs(conf)), vmax=np.nanmax(abs(conf)))\n",
    "        if titles is not None:\n",
    "            plt.title(titles[0] + ' - ' + titles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridmap(methods, ['3ea70747-8697-4e76-bc4f-319c6fa312b5', '89f4c672-f16a-4b08-a509-a94c82a6ebbd', '31d4cc8c-a727-4665-8643-2212eb519aa6', '26ea2435-d2d4-4988-b37e-d95934301d2f', 'a0626b3b-b34f-4353-8453-4abd769c130c', '9ae21984-b77f-4d12-be42-c4929c4d4125', '1cc0e452-8112-47ac-b939-f9ad5ae5edc6', '86d1bc60-d263-46be-b90f-ff9d9a30173a', '606653f0-b606-426c-9e8f-7770e8dad36a', '6ef54be8-cedf-40d7-a7c7-cda396b45d1c', '918ff2d4-b0d1-456d-96a1-e283e7838827'],\n",
    "# ['57976485-efee-4aae-95e2-4a2ac112ac3e', 'ff4eb4f9-0e6b-4336-bd66-057a02d2f663', '590d6225-04f7-4ba6-b8c7-0182262ccdf5', '78b3b890-bcc0-4fa6-bc7a-2569f12cee23', '0c875241-6230-41d1-9875-09a2c4c586c0', 'f608773d-99e2-49c9-b1d2-6857966d6977', 'f9a60776-ec0b-47fd-8895-27743c5c9911', '74b41430-89b3-4c1c-a058-9e01bb05480a', '45679ee3-d077-4e5a-83cc-77d4670d27ea', '1e7573db-8821-4cd7-b243-3f4fe9d31553', 'ad3fa7bc-8a5a-4fa6-a2b1-5d3072597e02'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a4aedbe07a0908b7e4bcbb5b24e255736426370940ab7ed4cb0f0eb179b2097"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}