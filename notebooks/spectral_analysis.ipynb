{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from glob import glob\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "display(HTML(\"<style>\"\n",
    "    + \"#notebook { padding-top:0px; } \" \"\"\n",
    "    + \".container { width:100%; } \"\n",
    "    + \".end_space { min-height:0px; } \"\n",
    "    + \"</style>\"))\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_exp_info(exp: dict):\n",
    "    print(f'model: {exp[\"model\"]} {exp[\"approach\"]}')\n",
    "    print({k: exp[k] for k in exp if k not in ['logs', 'results', 'knowledge']})\n",
    "\n",
    "# usage example:  show_exp_images(experiments[0], True)\n",
    "def show_exp_images(exp: dict, show_origins=False):\n",
    "    for task in exp['results']:\n",
    "        cur_images = exp['results'][task]['images']\n",
    "        fig, axs = plt.subplots(2, 5, figsize=(15, 8))\n",
    "        fig.suptitle(f'TASK {task} {exp[\"knowledge\"][task]}', fontsize=30)\n",
    "        for r, row in enumerate(axs):\n",
    "            for c, cell in enumerate(row):\n",
    "                idx = r*5 + c\n",
    "                image = np.zeros((28, 28, 3), dtype=float)\n",
    "                cell.set_title(cur_images[idx]['label'])\n",
    "                orig = np.array(cur_images[idx]['original'][0])\n",
    "                recon = np.array(cur_images[idx]['reconstruction'][0]).clip(0, 1)\n",
    "                if show_origins:\n",
    "                    image[:,:,1] = orig\n",
    "                image[:,:,0] = recon\n",
    "                image[:,:,2] = recon\n",
    "                cell.imshow(image)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_D_L_torch(data: torch.Tensor, sigma=1.):\n",
    "    dist_matrix = ((data[None, ...] - data.unsqueeze(1)) ** 2).sum(-1)\n",
    "    # compute affinity matrix\n",
    "    A = torch.exp(-dist_matrix / (sigma ** 2))\n",
    "\n",
    "    # compute degree matrix\n",
    "    D = torch.diag(A.sum(1))\n",
    "    # compute laplacian\n",
    "    L = D - A\n",
    "    return A, D, L\n",
    "\n",
    "def find_eig_torch(laplacian: torch.Tensor):\n",
    "    eigenvalues, eigenvectors = torch.linalg.eig(laplacian)\n",
    "    eigenvalues = eigenvalues.to(float)\n",
    "    eigenvectors = eigenvectors.to(float)\n",
    "    sorted_indices = torch.argsort(eigenvalues)\n",
    "    eigenvalues, eigenvectors = eigenvalues[sorted_indices], eigenvectors[:,sorted_indices]\n",
    "#     print(eigenvalues,'\\n'*2 ,eigenvectors)\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "def normalize_A_torch(a_m, d_m):\n",
    "    return torch.sqrt(torch.linalg.inv(d_m))@a_m@torch.sqrt(torch.linalg.inv(d_m))\n",
    "\n",
    "def dir_energy(data: torch.Tensor, sigma=1):\n",
    "    A, D, L = calc_D_L_torch(data, sigma=sigma)\n",
    "    eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "    energy = calc_energy_from_values(eigenvalues)\n",
    "    return energy\n",
    "\n",
    "def calc_energy_from_values(values: torch.Tensor):\n",
    "    nsamples = len(values)\n",
    "    max_value = nsamples * (nsamples - 1)\n",
    "    dir_energy = values.sum()\n",
    "    energy_p = dir_energy / max_value\n",
    "    return energy_p.cpu().item()\n",
    "\n",
    "def dir_energy_normal(data: torch.Tensor):\n",
    "    A, D, L = calc_D_L_torch(data)\n",
    "    L_norm = torch.eye(A.shape[0]).to(device)-normalize_A_torch(A, D)\n",
    "    eigenvalues, eigenvectors = find_eig_torch(L_norm)\n",
    "    nsamples = len(data)\n",
    "    max_value = nsamples - 1\n",
    "    dir_energy = eigenvalues.sum()\n",
    "    energy_p = dir_energy / max_value\n",
    "    return energy_p.cpu().item()\n",
    "\n",
    "def flatten_list(l: List[List[any]]) -> List[any]:\n",
    "    return [item for line in l for item in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logs_path = 'C:\\\\Users\\\\emace\\\\AImageLab\\\\SRV-Continual\\\\results\\\\canomaly\\\\logs'\n",
    "# logs_path = '../storage/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_dict = {}\n",
    "environments = []\n",
    "for log_file in glob(logs_path + '/**rec**/*.pyd', recursive=True):\n",
    "    print(log_file)\n",
    "    with open(log_file, 'r') as f:\n",
    "        props_list = [prop.split('-', 1) for prop in log_file.replace(logs_path, '').split('\\\\')[1:-1]]\n",
    "        props = {prop[0]: prop[1] for prop in props_list}\n",
    "        exps = []\n",
    "        for i, line in enumerate(f.readlines()):\n",
    "            try:\n",
    "                exps.append(literal_eval(line.replace('nan', 'None')))\n",
    "            except:\n",
    "                print(f'Unparsed line {i}:\\n\\t{exps[:-1]}\\n-->\\t{line}')\n",
    "\n",
    "        environments.append({'env': props, 'exps': exps})\n",
    "\n",
    "        exps = {exp['id']: exp for exp in exps}\n",
    "        exp_dict = {**exp_dict, **exps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_list = environments[0]['exps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_exp_energies(exp: dict, index=0, sigma=1,):\n",
    "    print_exp_info(exp)\n",
    "    model = exp['model']\n",
    "    app = exp['approach']\n",
    "    name = model + ' ' + app + ' ' + str(index)\n",
    "#     sigma = 10 if exp['model'] != 'rec-vae'\n",
    "    exp_df = pd.DataFrame(columns=['current', 'past'])\n",
    "    exp_df.columns = pd.MultiIndex.from_product([[name], ['current', 'past']])\n",
    "    for task_id in exp['results']:\n",
    "        task_idx = int(task_id)\n",
    "        task = exp['results'][task_id]\n",
    "        targets = torch.tensor(task['targets'], device=device)\n",
    "        latents = torch.tensor(task['latents'], device=device)\n",
    "        knowledge = [k for k in exp['knowledge'].values()]\n",
    "        for i in range(1, len(knowledge)):\n",
    "            knowledge[i] = [k for k in knowledge[i] if k not in flatten_list(knowledge[:i])]\n",
    "\n",
    "        cur_latents = latents[np.isin(targets.cpu(), knowledge[task_idx])]\n",
    "        past_latents = latents[np.isin(targets.cpu(), flatten_list(knowledge[:task_idx+1]))]\n",
    "        fut_latents = latents[np.isin(targets.cpu(), flatten_list(knowledge[task_idx:]))]\n",
    "        \n",
    "        cur_energy = dir_energy(cur_latents, sigma)\n",
    "        past_energy = dir_energy(past_latents, sigma)\n",
    "        # tot_energy = dir_energy(latents, sigma)\n",
    "        exp_df.loc[task_idx, (name, slice(None))] = cur_energy,past_energy # ,tot_energy\n",
    "        \n",
    "        print(f'{task_idx}. Task {task_id} ({knowledge[task_idx]})\\n'\n",
    "              f'current:        energy {cur_energy:.4f}     \\tmean {cur_latents.mean():.3f} ± {cur_latents.std():.3f}\\n'\n",
    "              f'with past:      energy {past_energy:.4f}    \\tmean {past_latents.mean():.3f} ± {past_latents.std():.3f}\\n'\n",
    "#               f'with future:    energy {dir_energy(fut_latents, sigma):.4f}     \\tmean {fut_latents.mean():.3f} ± {fut_latents.std():.3f}\\n'\n",
    "#               f'total:          energy {tot_energy:.4f}      \\tmean {latents.mean():.3f} ± {latents.std():.3f}'\n",
    "            )\n",
    "    return exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sigma = 10\n",
    "experiments = [x for x in exp_list if 'rec-vae' in x['model']\n",
    "#                and len(x['results'])>1 \n",
    "               and x['n_epochs']>1\n",
    "               and x['optim'] == 'adam'\n",
    "              ]\n",
    "total_list = []\n",
    "for num, exp in enumerate(experiments):    \n",
    "    print(f'--------------- {num} ---------------\\n')\n",
    "    exp_df = show_exp_energies(exp, num, sigma=sigma)\n",
    "    print('\\n-------------------------\\n')\n",
    "    total_list.append(exp_df)\n",
    "\n",
    "df_total = pd.concat(total_list, axis=1)\n",
    "\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp = exp_list[0]\n",
    "figsize = (20, 10)\n",
    "limit = 100\n",
    "\n",
    "def show_analysis(exp: dict):\n",
    "    print_exp_info(exp)\n",
    "    for task_id in exp['results']:\n",
    "        task_idx = int(task_id)\n",
    "        task = exp['results'][task_id]\n",
    "        targets = torch.tensor(task['targets'], device=device)\n",
    "        latents = torch.tensor(task['latents'], device=device)\n",
    "        knowledge = [k for k in exp['knowledge'].values()]\n",
    "        for i in range(1, len(knowledge)):\n",
    "            knowledge[i] = [k for k in knowledge[i] if k not in flatten_list(knowledge[:i])]\n",
    "\n",
    "        cur_latents = latents[np.isin(targets.cpu(), knowledge[task_idx])]\n",
    "        past_latents = latents[np.isin(targets.cpu(), flatten_list(knowledge[:task_idx+1]))]\n",
    "        fut_latents = latents[np.isin(targets.cpu(), flatten_list(knowledge[task_idx:]))]\n",
    "        past_targets = targets[np.isin(targets.cpu(), flatten_list(knowledge[:task_idx+1]))]\n",
    "\n",
    "\n",
    "        targets_knowledge = targets.clone()\n",
    "        for num, kn in enumerate(knowledge):\n",
    "            targets_knowledge[torch.isin(targets, torch.Tensor(kn).to(device))] = num\n",
    "\n",
    "        fig, ax = plt.subplots(2, 3, figsize=figsize)\n",
    "        ax = np.array(ax).flatten().tolist()\n",
    "        A, D, L = calc_D_L_torch(cur_latents, sigma=sigma)\n",
    "        eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "        # eigenvalues /= len(cur_latents)\n",
    "        ax[0].plot(eigenvalues[1:limit].cpu(), '*')\n",
    "        ax[0].set_title(f'Current E={calc_energy_from_values(eigenvalues)}\\nEigenvalues')\n",
    "\n",
    "        A, D, L = calc_D_L_torch(latents, sigma=sigma)\n",
    "        print((D.sum(1)-1).mean().item(),(D.sum(1)-1).std().item(), (D.sum(1)-1).min().item(), (D.sum(1)-1).max().item())\n",
    "        eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "        # eigenvalues /= len(past_latents)\n",
    "        # ax[1].plot(eigenvalues[1:limit].cpu(), '*')\n",
    "        filt_1 = (np.quantile(eigenvectors[:, 1].cpu().numpy(), .99) > eigenvectors[:, 1].cpu().numpy()) & (eigenvectors[:, 1].cpu().numpy() > np.quantile(eigenvectors[:, 1].cpu().numpy(), .01))\n",
    "        filt_2 = (np.quantile(eigenvectors[:, 2].cpu().numpy(), .99) > eigenvectors[:, 2].cpu().numpy()) & (eigenvectors[:, 1].cpu().numpy() > np.quantile(eigenvectors[:, 2].cpu().numpy(), .01))\n",
    "        filt_total = filt_1 & filt_2\n",
    "    #     ax[1].scatter(eigenvectors[filt_total, 1].cpu(), eigenvectors[filt_total, 2].cpu(), c=past_targets[filt_total].cpu())\n",
    "        ax[1].set_title(f'With Past E={calc_energy_from_values(eigenvalues)}\\nTSNE eigenvectors')\n",
    "\n",
    "        ts = TSNE(n_components=2, random_state=0, perplexity=30)\n",
    "        tr = ts.fit_transform(eigenvectors[:,:11].cpu().numpy())\n",
    "    #     ax[1].scatter(tr[:,0], tr[:,1], c=past_targets.cpu())\n",
    "        data = pd.DataFrame(np.concatenate([tr, targets_knowledge.cpu()[:, None]], axis=1), columns=['dim1','dim2','label'])\n",
    "        # fig,ax = plt.subplots(figsize=(10,10))\n",
    "        sns.scatterplot(x='dim1', y='dim2', hue='label', data=data, palette='tab10', ax=ax[1])\n",
    "\n",
    "        plt.suptitle(f'{task_idx}. Task {task_id} ({knowledge[task_idx]})')\n",
    "        ts = TSNE(n_components=2, perplexity=30, random_state=0)\n",
    "        tr = ts.fit_transform(latents.cpu().numpy())\n",
    "        data = pd.DataFrame(np.concatenate([tr, targets_knowledge.cpu()[:, None]], axis=1), columns=['dim1','dim2','label'])\n",
    "        # fig,ax = plt.subplots(figsize=(10,10))\n",
    "        ax[2].set_title(f'TSNE latent space')\n",
    "        sns.scatterplot(x='dim1', y='dim2', hue='label', data=data, palette='tab10', ax=ax[2])\n",
    "\n",
    "        centroids = pd.DataFrame(np.concatenate([latents.cpu().numpy(), targets_knowledge.cpu().numpy()[:, None]],1),\n",
    "        columns=[i for i in range(latents.shape[1])]+['label']).groupby('label').agg([np.mean, np.std])\n",
    "        arr_centr = centroids.loc[:, (slice(None), 'mean')].values\n",
    "        dist_matrix = ((arr_centr[None, ...] - np.expand_dims(arr_centr, 1)) ** 2).sum(-1)\n",
    "        ax[3].set_title(f'Centroids mutual distances')\n",
    "        ax[4].set_title(f'Centroids standard deviation')\n",
    "        sns.heatmap(dist_matrix, annot=True, ax = ax[3])\n",
    "        sns.heatmap(centroids.loc[:, (slice(None), 'std')].mean(1).to_frame(),annot=True,ax=ax[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compare_exps(exps: list[dict]):\n",
    "    print('Comparing experiments:')\n",
    "    for exp in exps:\n",
    "        print_exp_info(exp)\n",
    "    figsize = (5*len(exps)+5, 25)\n",
    "    limit = 100\n",
    "    for task_id in exps[0]['results']:\n",
    "        task_idx = int(task_id)\n",
    "        knowledge = [k for k in exps[0]['knowledge'].values()]\n",
    "        for i in range(1, len(knowledge)):\n",
    "            knowledge[i] = [k for k in knowledge[i] if k not in flatten_list(knowledge[:i])]\n",
    "\n",
    "        fig, ax = plt.subplots(5, len(exps), figsize=figsize)\n",
    "        plt.suptitle(f'{task_idx}. Task {task_id} ({knowledge[task_idx]})')\n",
    "\n",
    "        for exp_idx, exp in enumerate(exps):\n",
    "            task = exp['results'][task_id]\n",
    "            targets = torch.tensor(task['targets'], device=device)\n",
    "            latents = torch.tensor(task['latents'], device=device)\n",
    "\n",
    "            cur_latents = latents[np.isin(targets.cpu(), knowledge[task_idx])]\n",
    "            past_latents = latents[np.isin(targets.cpu(), flatten_list(knowledge[:task_idx+1]))]\n",
    "\n",
    "            targets_knowledge = targets.clone()\n",
    "            for num, kn in enumerate(knowledge):\n",
    "                targets_knowledge[torch.isin(targets, torch.Tensor(kn).to(device))] = num\n",
    "\n",
    "            ax_idx = 0\n",
    "            ax[ax_idx][exp_idx].set_title(f'{exp[\"model\"]} {exp[\"approach\"]}'\n",
    "                            f'\\nCurrent E={dir_energy(cur_latents, sigma)}'\n",
    "                            f'\\nPast E={dir_energy(past_latents, sigma)}\\n'\n",
    "                            f'\\nCurrent first {limit} Eigenvalues')\n",
    "            A, D, L = calc_D_L_torch(cur_latents, sigma=sigma)\n",
    "            eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "            ax[ax_idx][exp_idx].plot(eigenvalues[1:limit].cpu(), '*')\n",
    "            ax_idx += 1\n",
    "\n",
    "            A, D, L = calc_D_L_torch(past_latents, sigma=sigma)\n",
    "            eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "            ax[ax_idx][exp_idx].plot(eigenvalues[1:limit].cpu(), '*')\n",
    "            ax[ax_idx][exp_idx].set_title(f'Past first {limit} Eigenvalues')\n",
    "            ax_idx += 1\n",
    "\n",
    "            A, D, L = calc_D_L_torch(latents, sigma=sigma)\n",
    "            eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "            ev_limit = 11\n",
    "            ts = TSNE(n_components=2, random_state=0, perplexity=30, init='random', learning_rate='auto')\n",
    "            tr = ts.fit_transform(eigenvectors[:,:ev_limit].cpu().numpy())\n",
    "            data = pd.DataFrame(np.concatenate([tr, targets_knowledge.cpu()[:, None]], axis=1), columns=['dim1','dim2','label'])\n",
    "            sns.scatterplot(x='dim1', y='dim2', hue='label', data=data, palette='tab10', ax=ax[ax_idx][exp_idx])\n",
    "            ax[ax_idx][exp_idx].set_title(f'TSNE first {ev_limit} eigenvectors')\n",
    "            ax_idx += 1\n",
    "\n",
    "            ts = TSNE(n_components=2, random_state=0, perplexity=30, init='random', learning_rate='auto')\n",
    "            tr = ts.fit_transform(latents.cpu().numpy())\n",
    "            data = pd.DataFrame(np.concatenate([tr, targets_knowledge.cpu()[:, None]], axis=1), columns=['dim1','dim2','label'])\n",
    "            ax[ax_idx][exp_idx].set_title(f'TSNE latent space')\n",
    "            sns.scatterplot(x='dim1', y='dim2', hue='label', data=data, palette='tab10', ax=ax[ax_idx][exp_idx])\n",
    "            ax_idx += 1\n",
    "\n",
    "            centroids = pd.DataFrame(np.concatenate([latents.cpu().numpy(), targets_knowledge.cpu().numpy()[:, None]],1),\n",
    "                                     columns=[i for i in range(latents.shape[1])]+['label']).groupby('label').agg([np.mean, np.std])\n",
    "            arr_centr = centroids.loc[:, (slice(None), 'mean')].values\n",
    "            dist_matrix = ((arr_centr[None, ...] - np.expand_dims(arr_centr, 1)) ** 2).sum(-1)\n",
    "            ax[ax_idx][exp_idx].set_title(f'Centroids mutual distances')\n",
    "            sns.heatmap(dist_matrix, annot=True, ax = ax[ax_idx][exp_idx])\n",
    "            ax_idx += 1\n",
    "            # ax[ax_idx][exp_idx].set_title(f'Centroids standard deviation')\n",
    "            # sns.heatmap(centroids.loc[:, (slice(None), 'std')].mean(1).to_frame(),annot=True,ax=ax[ax_idx][exp_idx])\n",
    "\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compare_exps([exp_list[0], exp_list[1]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_exp_info(exp_list[0])\n",
    "show_exp_images(exp_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_exp_info(exp_list[1])\n",
    "show_exp_images(exp_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}