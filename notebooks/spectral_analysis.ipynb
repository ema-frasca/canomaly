{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from glob import glob\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "display(HTML(\"<style>\"\n",
    "    + \"#notebook { padding-top:0px; } \" \"\"\n",
    "    + \".container { width:100%; } \"\n",
    "    + \".end_space { min-height:0px; } \"\n",
    "    + \"</style>\"))\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_exp_info(exp: dict):\n",
    "    print(f'model: {exp[\"model\"]} {exp[\"approach\"]}')\n",
    "    print({k: exp[k] for k in exp if k not in ['logs', 'results', 'knowledge']})\n",
    "\n",
    "# usage example:  show_exp_images(experiments[0], True)\n",
    "def show_exp_images(exp: dict, show_origins=False):\n",
    "    for task in exp['results']:\n",
    "        cur_images = exp['results'][task]['images']\n",
    "        fig, axs = plt.subplots(2, 5, figsize=(15, 8))\n",
    "        fig.suptitle(f'TASK {task} {exp[\"knowledge\"][task]}', fontsize=30)\n",
    "        for r, row in enumerate(axs):\n",
    "            for c, cell in enumerate(row):\n",
    "                idx = r*5 + c\n",
    "                image = np.zeros((28, 28, 3), dtype=float)\n",
    "                cell.set_title(cur_images[idx]['label'])\n",
    "                orig = np.array(cur_images[idx]['original'][0])\n",
    "                recon = np.array(cur_images[idx]['reconstruction'][0]).clip(0, 1)\n",
    "                if show_origins:\n",
    "                    image[:,:,1] = orig\n",
    "                image[:,:,0] = recon\n",
    "                image[:,:,2] = recon\n",
    "                cell.imshow(image)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_ADL_from_dist(dist_matrix: torch.Tensor, sigma=1.):\n",
    "    # compute affinity matrix, heat_kernel\n",
    "    A = torch.exp(-dist_matrix / (sigma ** 2))\n",
    "    # compute degree matrix\n",
    "    D = torch.diag(A.sum(1))\n",
    "    # compute laplacian\n",
    "    L = D - A\n",
    "    return A, D, L\n",
    "\n",
    "def calc_euclid_dist(data: torch.Tensor):\n",
    "    return ((data.unsqueeze(0) - data.unsqueeze(1)) ** 2).sum(-1)\n",
    "\n",
    "def calc_dist_weiss(nu: torch.Tensor, logvar: torch.Tensor):\n",
    "    var = logvar.exp()\n",
    "    edist = calc_euclid_dist(nu)\n",
    "    wdiff = (var.unsqueeze(0) + var.unsqueeze(1) -2*(torch.sqrt(var.unsqueeze(0)*var.unsqueeze(1)))).sum(-1)\n",
    "    return edist + wdiff\n",
    "\n",
    "def calc_ADL_knn(distances: torch.Tensor, k: int, symmetric: bool = True):\n",
    "    new_A = torch.clone(distances)\n",
    "    mask = torch.eye(new_A.shape[0])\n",
    "    new_A[mask==1] = +torch.inf\n",
    "\n",
    "    final_A = torch.zeros_like(new_A)\n",
    "    idxes = new_A.topk(k, largest=False)[1]\n",
    "    final_A[torch.arange(len(idxes)).unsqueeze(1), idxes] = 1\n",
    "\n",
    "    if symmetric:\n",
    "        final_A = ((final_A + final_A.T) > 0).float()\n",
    "        # final_A = 0.5*(final_A + final_A.T)\n",
    "\n",
    "    # compute degree matrix\n",
    "    D = torch.diag(final_A.sum(1))\n",
    "    # compute laplacian\n",
    "    L = D - final_A\n",
    "    return final_A, D, L\n",
    "\n",
    "def calc_ADL(data: torch.Tensor, sigma=1.):\n",
    "    return calc_ADL_from_dist(calc_euclid_dist(data), sigma)\n",
    "\n",
    "def find_eigs(laplacian: torch.Tensor):\n",
    "    eigenvalues, eigenvectors = torch.linalg.eig(laplacian)\n",
    "    eigenvalues = eigenvalues.to(float)\n",
    "    eigenvectors = eigenvectors.to(float)\n",
    "    sorted_indices = torch.argsort(eigenvalues)\n",
    "    eigenvalues, eigenvectors = eigenvalues[sorted_indices], eigenvectors[:,sorted_indices]\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "def calc_energy_from_values(values: torch.Tensor, norm=False):\n",
    "    nsamples = len(values)\n",
    "    max_value = nsamples - 1 if norm else nsamples * (nsamples - 1)\n",
    "    dir_energy = values.sum()\n",
    "    energy_p = dir_energy / max_value\n",
    "    return energy_p.cpu().item()\n",
    "\n",
    "def normalize_A(A, D):\n",
    "    return torch.sqrt(torch.linalg.inv(D)) @ A @ torch.sqrt(torch.linalg.inv(D))\n",
    "\n",
    "def dir_energy_normal(data: torch.Tensor, sigma=1.):\n",
    "    A, D, L = calc_ADL(data, sigma)\n",
    "    L_norm = torch.eye(A.shape[0]).to(device) - normalize_A(A, D)\n",
    "    eigenvalues, eigenvectors = find_eigs(L_norm)\n",
    "    energy = calc_energy_from_values(eigenvalues, norm=True)\n",
    "    return energy, eigenvalues, eigenvectors\n",
    "\n",
    "def dir_energy(data: torch.Tensor, sigma=1):\n",
    "    A, D, L = calc_ADL(data, sigma=sigma)\n",
    "    eigenvalues, eigenvectors = find_eigs(L)\n",
    "    energy = calc_energy_from_values(eigenvalues)\n",
    "    return energy\n",
    "\n",
    "def laplacian_analysis(data: torch.Tensor, sigma=1., knn=0, logvars: torch.Tensor=None,\n",
    "                       norm_lap=False, norm_eigs=False):\n",
    "    if logvars is None:\n",
    "        distances = calc_euclid_dist(data)\n",
    "    else:\n",
    "        distances = calc_dist_weiss(data, logvars)\n",
    "    if knn > 0:\n",
    "        A, D, L = calc_ADL_knn(distances, knn, symmetric=True)\n",
    "    else:\n",
    "        A, D, L = calc_ADL_from_dist(distances, sigma)\n",
    "    if norm_lap:\n",
    "        L = torch.eye(A.shape[0]).to(device) - normalize_A(A, D)\n",
    "    eigenvalues, eigenvectors = find_eigs(L)\n",
    "    energy = calc_energy_from_values(eigenvalues, norm=norm_lap)\n",
    "    if norm_eigs and not norm_lap:\n",
    "        eigenvalues = eigenvalues / (len(eigenvalues))\n",
    "    return energy, eigenvalues, eigenvectors, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def flatten_list(l: List[List[any]]) -> List[any]:\n",
    "    return [item for line in l for item in line]\n",
    "\n",
    "def get_knowledge_list(exp: dict):\n",
    "    knowledge = [k for k in exp['knowledge'].values()]\n",
    "    for i in range(1, len(knowledge)):\n",
    "        knowledge[i] = [k for k in knowledge[i] if k not in flatten_list(knowledge[:i])]\n",
    "    return knowledge"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logs_path = 'C:\\\\Users\\\\emace\\\\AImageLab\\\\SRV-Continual\\\\results\\\\canomaly\\\\logs'\n",
    "logs_path = '/nas/softechict-nas-2/efrascaroli/canomaly-data/logs'\n",
    "# logs_path = '../storage/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_dict = {}\n",
    "environments = []\n",
    "for log_file in glob(logs_path + '/**rec**/*.pyd', recursive=True):\n",
    "    print(log_file)\n",
    "    with open(log_file, 'r') as f:\n",
    "        props_list = [prop.split('-', 1) for prop in log_file.replace(logs_path, '').split('\\\\')[1:-1]]\n",
    "        props = {prop[0]: prop[1] for prop in props_list}\n",
    "        exps = []\n",
    "        for i, line in enumerate(f.readlines()):\n",
    "            try:\n",
    "                exps.append(literal_eval(line.replace('nan', 'None')))\n",
    "            except:\n",
    "                print(f'Unparsed line {i}:\\n\\t{exps[:-1]}\\n-->\\t{line}')\n",
    "\n",
    "        environments.append({'env': props, 'exps': exps})\n",
    "\n",
    "        exps = {exp['id']: exp for exp in exps}\n",
    "        exp_dict = {**exp_dict, **exps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_list = environments[0]['exps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def task_reduction(task: dict, knowledge_list: list, task_max=1000):\n",
    "    rec_errs = torch.tensor(task['rec_errs'], device=device)\n",
    "    latents = torch.tensor(task['latents'], device=device)\n",
    "    targets = torch.tensor(task['targets'], device=device)\n",
    "    logvars = torch.tensor(task['logvars'], device=device) if 'logvars' in task else None\n",
    "    class_quantity = {label: task_max // (len(group)) for group in knowledge_list for label in group}\n",
    "    index_list = []\n",
    "    for label in class_quantity:\n",
    "        idxes = (targets == label).nonzero(as_tuple=True)[0][:class_quantity[label]]\n",
    "        index_list.append(idxes)\n",
    "    idxes = torch.cat(index_list)\n",
    "    rec_errs = rec_errs[idxes]\n",
    "    targets = targets[idxes]\n",
    "    latents = latents[idxes]\n",
    "    logvars = logvars[idxes] if logvars is not None else None\n",
    "    return rec_errs, latents, targets, logvars\n",
    "\n",
    "# rec_errs, latents, targets, logvars = task_reduction(exp_list[0]['results']['0'], get_knowledge_list(exp_list[3]), 250)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_exp_energies(exp: dict, index=0, sigma=1, max_task=1000, print_details=True):\n",
    "    print_exp_info(exp)\n",
    "    model = exp['model']\n",
    "    app = exp['approach']\n",
    "    name = model + ' ' + app + ' ' + str(index)\n",
    "    # sigma = 10 if exp['model'] != 'rec-vae'\n",
    "    exp_df = pd.DataFrame(columns=['current', 'past'])\n",
    "    exp_df.columns = pd.MultiIndex.from_product([[name], ['current', 'past']])\n",
    "\n",
    "    knowledge = get_knowledge_list(exp)\n",
    "\n",
    "    for task_id in exp['results']:\n",
    "        task_idx = int(task_id)\n",
    "        task = exp['results'][task_id]\n",
    "        rec_errs, latents, targets, logvars = task_reduction(task, knowledge, task_max=max_task)\n",
    "\n",
    "        cur_latents = latents[np.isin(targets.cpu(), knowledge[task_idx])]\n",
    "        past_latents = latents[np.isin(targets.cpu(), flatten_list(knowledge[:task_idx+1]))]\n",
    "        # fut_latents = latents[np.isin(targets.cpu(), flatten_list(knowledge[task_idx:]))]\n",
    "        \n",
    "        cur_energy = dir_energy(cur_latents, sigma)\n",
    "        past_energy = dir_energy(past_latents, sigma)\n",
    "        # tot_energy = dir_energy(latents, sigma)\n",
    "        exp_df.loc[task_idx, (name, slice(None))] = cur_energy,past_energy # ,tot_energy\n",
    "        if print_details:\n",
    "            print(f'{task_idx}. Task {task_id} ({knowledge[task_idx]})\\n'\n",
    "                  f'current:        energy {cur_energy:.4f}     \\tmean {cur_latents.mean():.3f} ± {cur_latents.std():.3f}\\n'\n",
    "                  f'with past:      energy {past_energy:.4f}    \\tmean {past_latents.mean():.3f} ± {past_latents.std():.3f}\\n'\n",
    "    #               f'with future:    energy {dir_energy(fut_latents, sigma):.4f}     \\tmean {fut_latents.mean():.3f} ± {fut_latents.std():.3f}\\n'\n",
    "    #               f'total:          energy {tot_energy:.4f}      \\tmean {latents.mean():.3f} ± {latents.std():.3f}'\n",
    "                )\n",
    "    return exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sigma = 10\n",
    "experiments = [x for x in exp_list if 'rec-vae' in x['model']\n",
    "#                and len(x['results'])>1 \n",
    "               and x['n_epochs']>1\n",
    "               and x['optim'] == 'adam'\n",
    "              ]\n",
    "total_list = []\n",
    "print_all = False\n",
    "for num, exp in enumerate(experiments):\n",
    "    if print_all:\n",
    "        print(f'--------------- {num} ---------------\\n')\n",
    "    exp_df = show_exp_energies(exp, num, sigma=sigma, max_task=250, print_details=print_all)\n",
    "    if print_all:\n",
    "        print('\\n-------------------------\\n')\n",
    "    total_list.append(exp_df)\n",
    "\n",
    "df_total = pd.concat(total_list, axis=1)\n",
    "\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp = exp_list[4]\n",
    "figsize = (20, 10)\n",
    "limit = 100\n",
    "\n",
    "def show_analysis(exp: dict, max_task=1000):\n",
    "    print_exp_info(exp)\n",
    "    nrows = 3\n",
    "    ncols = len(exp['results'])\n",
    "    figsize = (5*ncols, 5*nrows+5)\n",
    "    limit = 100\n",
    "    sigma = 10\n",
    "\n",
    "    fig, ax = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    plt.suptitle(f'Evolution {exp[\"model\"]} {exp[\"approach\"]}')\n",
    "    pbar = tqdm(desc=f'Coputing', total=nrows*ncols, leave=False)\n",
    "\n",
    "    for task_id in exp['results']:\n",
    "        task_idx = int(task_id)\n",
    "        task = exp['results'][task_id]\n",
    "        knowledge = get_knowledge_list(exp)\n",
    "        rec_errs, latents, targets, logvars = task_reduction(task, knowledge, task_max=max_task)\n",
    "\n",
    "        cur_nu = latents[np.isin(targets.cpu(), knowledge[task_idx])]\n",
    "        past_nu = latents[np.isin(targets.cpu(), flatten_list(knowledge[:task_idx+1]))]\n",
    "        first_nu = latents[np.isin(targets.cpu(), knowledge[0])]\n",
    "\n",
    "        cur_logvars = logvars[np.isin(targets.cpu(), knowledge[task_idx])]\n",
    "        past_logvars = logvars[np.isin(targets.cpu(), flatten_list(knowledge[:task_idx+1]))]\n",
    "        first_logvars = logvars[np.isin(targets.cpu(), knowledge[0])]\n",
    "\n",
    "        targets_knowledge = targets.clone()\n",
    "        for num, kn in enumerate(knowledge):\n",
    "            targets_knowledge[torch.isin(targets, torch.Tensor(kn).to(device))] = num\n",
    "\n",
    "        ax_idx = 0\n",
    "\n",
    "        A, D, L = calc_D_L_from_dist(calc_dist_weiss(cur_nu, cur_logvars), sigma)\n",
    "        eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "        energy = calc_energy_from_values(eigenvalues)\n",
    "        # energy, eigenvalues, eigenvectors = dir_energy_normal(cur_latents, sigma=sigma)\n",
    "        ax[ax_idx][task_idx].plot(eigenvalues[:limit].cpu(), '*')\n",
    "        ax[ax_idx][task_idx].set_title(f'{task_idx}. Task {task_id} ({knowledge[task_idx]})'\n",
    "                        f'\\nCurrent first {limit} Eigenvalues'\n",
    "                        f'\\nenergy: {energy:.4f}')\n",
    "        # ax[ax_idx][task_idx].set_ylim([0, 1])\n",
    "        ax_idx += 1\n",
    "        pbar.update()\n",
    "\n",
    "        A, D, L = calc_D_L_from_dist(calc_dist_weiss(past_nu, past_logvars), sigma)\n",
    "        eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "        energy = calc_energy_from_values(eigenvalues)\n",
    "        # energy, eigenvalues, eigenvectors = dir_energy_normal(past_latents, sigma=sigma)\n",
    "        ax[ax_idx][task_idx].plot(eigenvalues[:limit].cpu(), '*')\n",
    "        ax[ax_idx][task_idx].set_title(f'Past first {limit} Eigenvalues'\n",
    "                                       f'\\nenergy: {energy:.4f}')\n",
    "        # ax[ax_idx][task_idx].set_ylim([0, 1])\n",
    "        ax_idx += 1\n",
    "        pbar.update()\n",
    "\n",
    "        A, D, L = calc_D_L_from_dist(calc_dist_weiss(first_nu, first_logvars), sigma)\n",
    "        eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "        energy = calc_energy_from_values(eigenvalues)\n",
    "        # energy, eigenvalues, eigenvectors = dir_energy_normal(first_latents, sigma=sigma)\n",
    "        ax[ax_idx][task_idx].plot(eigenvalues[:limit].cpu(), '*')\n",
    "        ax[ax_idx][task_idx].set_title(f'Task 0 first {limit} Norm Eigenvalues'\n",
    "                                       f'\\nenergy: {energy:.4f}')\n",
    "        # ax[ax_idx][task_idx].set_ylim([0, 1])\n",
    "        ax_idx += 1\n",
    "        pbar.update()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_analysis(exp_list[4], max_task=250)\n",
    "show_analysis(exp_list[5], max_task=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def exp_evolution(exp: dict, max_task=250):\n",
    "    print('Experiment')\n",
    "    print_exp_info(exp)\n",
    "    nrows = 7\n",
    "    ncols = len(exp['results'])\n",
    "    figsize = (5*ncols, 5*nrows+5)\n",
    "    limit = 100\n",
    "    sigma = 3\n",
    "\n",
    "    fig, ax = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "    plt.suptitle(f'Evolution {exp[\"model\"]} {exp[\"approach\"]}')\n",
    "    pbar = tqdm(desc=f'Coputing', total=nrows*ncols, leave=False)\n",
    "\n",
    "    knowledge = get_knowledge_list(exp)\n",
    "\n",
    "    for task_id in exp['results']:\n",
    "        task_idx = int(task_id)\n",
    "        task = exp['results'][task_id]\n",
    "        rec_errs, latents, targets, logvars = task_reduction(task, knowledge, task_max=max_task)\n",
    "\n",
    "        cur_latents = latents[np.isin(targets.cpu(), knowledge[task_idx])]\n",
    "        past_latents = latents[np.isin(targets.cpu(), flatten_list(knowledge[:task_idx+1]))]\n",
    "\n",
    "        first_latents = latents[np.isin(targets.cpu(), knowledge[0])]\n",
    "\n",
    "        targets_knowledge = targets.clone()\n",
    "        for num, kn in enumerate(knowledge):\n",
    "            targets_knowledge[torch.isin(targets, torch.Tensor(kn).to(device))] = num\n",
    "\n",
    "        ax_idx = 0\n",
    "\n",
    "        energy, eigenvalues, eigenvectors = dir_energy_normal(cur_latents, sigma=sigma)\n",
    "        ax[ax_idx][task_idx].plot(eigenvalues[:limit].cpu(), '*')\n",
    "        ax[ax_idx][task_idx].set_title(f'{task_idx}. Task {task_id} ({knowledge[task_idx]})'\n",
    "                        f'\\nCurrent first {limit} Eigenvalues'\n",
    "                        f'\\nenergy: {energy:.4f}')\n",
    "        ax[ax_idx][task_idx].set_ylim([0, 1])\n",
    "        ax_idx += 1\n",
    "        pbar.update()\n",
    "\n",
    "        energy, eigenvalues, eigenvectors = dir_energy_normal(past_latents, sigma=sigma)\n",
    "        ax[ax_idx][task_idx].plot(eigenvalues[:limit].cpu(), '*')\n",
    "        ax[ax_idx][task_idx].set_title(f'Past first {limit} Eigenvalues'\n",
    "                                       f'\\nenergy: {energy:.4f}')\n",
    "        ax[ax_idx][task_idx].set_ylim([0, 1])\n",
    "        ax_idx += 1\n",
    "        pbar.update()\n",
    "\n",
    "        energy, eigenvalues, eigenvectors = dir_energy_normal(first_latents, sigma=sigma)\n",
    "        ax[ax_idx][task_idx].plot(eigenvalues[:limit].cpu(), '*')\n",
    "        ax[ax_idx][task_idx].set_title(f'Task 0 first {limit} Norm Eigenvalues'\n",
    "                                       f'\\nenergy: {energy:.4f}')\n",
    "        ax[ax_idx][task_idx].set_ylim([0, 1])\n",
    "        ax_idx += 1\n",
    "        pbar.update()\n",
    "\n",
    "        A, D, L = calc_D_L_torch(latents, sigma=sigma)\n",
    "        eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "        ev_limit = 11\n",
    "        ts = TSNE(n_components=2, random_state=0, perplexity=30, init='random', learning_rate='auto')\n",
    "        tr = ts.fit_transform(eigenvectors[:,:ev_limit].cpu().numpy())\n",
    "        data = pd.DataFrame(np.concatenate([tr, targets_knowledge.cpu()[:, None]], axis=1), columns=['dim1','dim2','label'])\n",
    "        sns.scatterplot(x='dim1', y='dim2', hue='label', data=data, palette='tab10', ax=ax[ax_idx][task_idx])\n",
    "        ax[ax_idx][task_idx].set_title(f'TSNE first {ev_limit} eigenvectors')\n",
    "        ax_idx += 1\n",
    "        pbar.update()\n",
    "\n",
    "        ev_limit = 5\n",
    "        ts = TSNE(n_components=2, random_state=0, perplexity=30, init='random', learning_rate='auto')\n",
    "        tr = ts.fit_transform(eigenvectors[:,:ev_limit].cpu().numpy())\n",
    "        data = pd.DataFrame(np.concatenate([tr, targets_knowledge.cpu()[:, None]], axis=1), columns=['dim1','dim2','label'])\n",
    "        sns.scatterplot(x='dim1', y='dim2', hue='label', data=data, palette='tab10', ax=ax[ax_idx][task_idx])\n",
    "        ax[ax_idx][task_idx].set_title(f'TSNE first {ev_limit} eigenvectors')\n",
    "        ax_idx += 1\n",
    "        pbar.update()\n",
    "\n",
    "        ts = TSNE(n_components=2, random_state=0, perplexity=30, init='random', learning_rate='auto')\n",
    "        tr = ts.fit_transform(latents.cpu().numpy())\n",
    "        data = pd.DataFrame(np.concatenate([tr, targets_knowledge.cpu()[:, None]], axis=1), columns=['dim1','dim2','label'])\n",
    "        ax[ax_idx][task_idx].set_title(f'TSNE latent space')\n",
    "        sns.scatterplot(x='dim1', y='dim2', hue='label', data=data, palette='tab10', ax=ax[ax_idx][task_idx])\n",
    "        ax_idx += 1\n",
    "        pbar.update()\n",
    "\n",
    "        centroids = pd.DataFrame(np.concatenate([latents.cpu().numpy(), targets_knowledge.cpu().numpy()[:, None]],1),\n",
    "                                 columns=[i for i in range(latents.shape[1])]+['label']).groupby('label').agg([np.mean, np.std])\n",
    "        arr_centr = centroids.loc[:, (slice(None), 'mean')].values\n",
    "        dist_matrix = ((arr_centr[None, ...] - np.expand_dims(arr_centr, 1)) ** 2).sum(-1)\n",
    "        ax[ax_idx][task_idx].set_title(f'Centroids mutual distances')\n",
    "        sns.heatmap(dist_matrix, annot=True, ax = ax[ax_idx][task_idx])\n",
    "        ax_idx += 1\n",
    "        pbar.update()\n",
    "\n",
    "    pbar.clear()\n",
    "    pbar.close()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "exp_evolution(exp_list[4])\n",
    "exp_evolution(exp_list[5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# latents = torch.tensor(exp_list[2]['results']['0']['latents'], device=device)\n",
    "# energy, neigenvalues, neigenvectors = dir_energy_normal(latents, sigma=3)\n",
    "# A, D, L = calc_D_L_torch(latents, sigma=10)\n",
    "# eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "# for i in range(10):\n",
    "#     fig, ax = plt.subplots(1, 2, figsize=(10, 5), sharey=True)\n",
    "#     plt.suptitle(f'Eigenvector {i}')\n",
    "#     ax[0].plot(eigenvectors[:, i].cpu(), '*')\n",
    "#     ax[0].set_title(f'Positives: {(eigenvectors[:, i] > 0).sum()}')\n",
    "#     ax[0].set_ylim([-1.1, 1.1])\n",
    "#     ax[1].plot(neigenvectors[:, i].cpu(), '*')\n",
    "#     ax[1].set_title(f'Positives: {(neigenvectors[:, i] > 0).sum()}')\n",
    "#     plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compare_exps(exps: list[dict], max_task=1000):\n",
    "    print('Comparing experiments:')\n",
    "    for exp in exps:\n",
    "        print_exp_info(exp)\n",
    "    nrows = 6\n",
    "    figsize = (5*len(exps), 5*nrows+5)\n",
    "    limit = 100\n",
    "\n",
    "    knowledge = get_knowledge_list(exps[0])\n",
    "\n",
    "    for task_id in exps[0]['results']:\n",
    "        task_idx = int(task_id)\n",
    "\n",
    "        fig, ax = plt.subplots(nrows, len(exps), figsize=figsize)\n",
    "        plt.suptitle(f'{task_idx}. Task {task_id} ({knowledge[task_idx]})')\n",
    "        pbar = tqdm(desc=f'Task {task_id}', total=nrows*len(exps), leave=False)\n",
    "\n",
    "        for exp_idx, exp in enumerate(exps):\n",
    "            task = exp['results'][task_id]\n",
    "            rec_errs, latents, targets, logvars = task_reduction(task, knowledge, task_max=max_task)\n",
    "\n",
    "            cur_latents = latents[np.isin(targets.cpu(), knowledge[task_idx])]\n",
    "            past_latents = latents[np.isin(targets.cpu(), flatten_list(knowledge[:task_idx+1]))]\n",
    "\n",
    "            targets_knowledge = targets.clone()\n",
    "            for num, kn in enumerate(knowledge):\n",
    "                targets_knowledge[torch.isin(targets, torch.Tensor(kn).to(device))] = num\n",
    "\n",
    "            ax_idx = 0\n",
    "            ax[ax_idx][exp_idx].set_title(f'{exp[\"model\"]} {exp[\"approach\"]}'\n",
    "                            f'\\nCurrent E={dir_energy(cur_latents, sigma)}'\n",
    "                            f'\\nPast E={dir_energy(past_latents, sigma)}\\n'\n",
    "                            f'\\nCurrent first {limit} Eigenvalues')\n",
    "            A, D, L = calc_D_L_torch(cur_latents, sigma=sigma)\n",
    "            eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "            ax[ax_idx][exp_idx].plot(eigenvalues[1:limit].cpu(), '*')\n",
    "            ax_idx += 1\n",
    "            pbar.update()\n",
    "\n",
    "            A, D, L = calc_D_L_torch(past_latents, sigma=sigma)\n",
    "            eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "            ax[ax_idx][exp_idx].plot(eigenvalues[1:limit].cpu(), '*')\n",
    "            ax[ax_idx][exp_idx].set_title(f'Past first {limit} Eigenvalues')\n",
    "            ax_idx += 1\n",
    "            pbar.update()\n",
    "\n",
    "            A, D, L = calc_D_L_torch(latents, sigma=sigma)\n",
    "            eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "            ev_limit = 11\n",
    "            ts = TSNE(n_components=2, random_state=0, perplexity=30, init='random', learning_rate='auto')\n",
    "            tr = ts.fit_transform(eigenvectors[:,:ev_limit].cpu().numpy())\n",
    "            data = pd.DataFrame(np.concatenate([tr, targets_knowledge.cpu()[:, None]], axis=1), columns=['dim1','dim2','label'])\n",
    "            sns.scatterplot(x='dim1', y='dim2', hue='label', data=data, palette='tab10', ax=ax[ax_idx][exp_idx])\n",
    "            ax[ax_idx][exp_idx].set_title(f'TSNE first {ev_limit} eigenvectors')\n",
    "            ax_idx += 1\n",
    "            pbar.update()\n",
    "\n",
    "            ev_limit = 5\n",
    "            ts = TSNE(n_components=2, random_state=0, perplexity=30, init='random', learning_rate='auto')\n",
    "            tr = ts.fit_transform(eigenvectors[:,:ev_limit].cpu().numpy())\n",
    "            data = pd.DataFrame(np.concatenate([tr, targets_knowledge.cpu()[:, None]], axis=1), columns=['dim1','dim2','label'])\n",
    "            sns.scatterplot(x='dim1', y='dim2', hue='label', data=data, palette='tab10', ax=ax[ax_idx][exp_idx])\n",
    "            ax[ax_idx][exp_idx].set_title(f'TSNE first {ev_limit} eigenvectors')\n",
    "            ax_idx += 1\n",
    "            pbar.update()\n",
    "\n",
    "            ts = TSNE(n_components=2, random_state=0, perplexity=30, init='random', learning_rate='auto')\n",
    "            tr = ts.fit_transform(latents.cpu().numpy())\n",
    "            data = pd.DataFrame(np.concatenate([tr, targets_knowledge.cpu()[:, None]], axis=1), columns=['dim1','dim2','label'])\n",
    "            ax[ax_idx][exp_idx].set_title(f'TSNE latent space')\n",
    "            sns.scatterplot(x='dim1', y='dim2', hue='label', data=data, palette='tab10', ax=ax[ax_idx][exp_idx])\n",
    "            ax_idx += 1\n",
    "            pbar.update()\n",
    "\n",
    "            centroids = pd.DataFrame(np.concatenate([latents.cpu().numpy(), targets_knowledge.cpu().numpy()[:, None]],1),\n",
    "                                     columns=[i for i in range(latents.shape[1])]+['label']).groupby('label').agg([np.mean, np.std])\n",
    "            arr_centr = centroids.loc[:, (slice(None), 'mean')].values\n",
    "            dist_matrix = ((arr_centr[None, ...] - np.expand_dims(arr_centr, 1)) ** 2).sum(-1)\n",
    "            ax[ax_idx][exp_idx].set_title(f'Centroids mutual distances')\n",
    "            sns.heatmap(dist_matrix, annot=True, ax = ax[ax_idx][exp_idx])\n",
    "            ax_idx += 1\n",
    "            pbar.update()\n",
    "            # ax[ax_idx][exp_idx].set_title(f'Centroids standard deviation')\n",
    "            # sns.heatmap(centroids.loc[:, (slice(None), 'std')].mean(1).to_frame(),annot=True,ax=ax[ax_idx][exp_idx])\n",
    "\n",
    "        pbar.close()\n",
    "        pbar.clear()\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx_to_cmp = []\n",
    "if len(idx_to_cmp) > 0:\n",
    "    compare_exps([exp_list[idx] for idx in idx_to_cmp], max_task=250)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx_to_show = [4, 5]\n",
    "for idx in idx_to_show:\n",
    "    print_exp_info(exp_list[idx])\n",
    "    show_exp_images(exp_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}