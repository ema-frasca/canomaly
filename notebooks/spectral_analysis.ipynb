{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from glob import glob\n",
    "from ast import literal_eval\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "display(HTML(\"<style>\"\n",
    "    + \"#notebook { padding-top:0px; } \" \"\"\n",
    "    + \".container { width:100%; } \"\n",
    "    + \".end_space { min-height:0px; } \"\n",
    "    + \"</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_exp_info(exp: dict):\n",
    "    print(f'model: {exp[\"model\"]} {exp[\"approach\"]}')\n",
    "    print({k: exp[k] for k in exp if k not in ['logs', 'results', 'knowledge']})\n",
    "\n",
    "# usage example:  show_exp_images(experiments[0], True)\n",
    "def show_exp_images(exp: dict, show_origins=False):\n",
    "    for task in exp['results']:\n",
    "        cur_images = exp['results'][task]['images']\n",
    "        fig, axs = plt.subplots(2, 5, figsize=(15, 8))\n",
    "        fig.suptitle(f'TASK {task} {exp[\"knowledge\"][task]}', fontsize=30)\n",
    "        for r, row in enumerate(axs):\n",
    "            for c, cell in enumerate(row):\n",
    "                idx = r*5 + c\n",
    "                image = np.zeros((28, 28, 3), dtype=float)\n",
    "                cell.set_title(cur_images[idx]['label'])\n",
    "                orig = np.array(cur_images[idx]['original'][0])\n",
    "                recon = np.array(cur_images[idx]['reconstruction'][0]).clip(0, 1)\n",
    "                if show_origins:\n",
    "                    image[:,:,1] = orig\n",
    "                image[:,:,0] = recon\n",
    "                image[:,:,2] = recon\n",
    "                cell.imshow(image)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_D_L_torch(data: torch.Tensor, sigma=1.):\n",
    "    dist_matrix = ((data[None, ...] - data.unsqueeze(1)) ** 2).sum(-1)\n",
    "    # compute affinity matrix\n",
    "    A = torch.exp(-dist_matrix / (sigma ** 2))\n",
    "\n",
    "    # compute degree matrix\n",
    "    D = torch.diag(A.sum(1))\n",
    "    # compute laplacian\n",
    "    L = D - A\n",
    "    return A, D, L\n",
    "\n",
    "def find_eig_torch(laplacian: torch.Tensor):\n",
    "    eigenvalues, eigenvectors = torch.linalg.eig(laplacian)\n",
    "    eigenvalues = eigenvalues.to(float)\n",
    "    eigenvectors = eigenvectors.to(float)\n",
    "    sorted_indices = torch.argsort(eigenvalues)\n",
    "    eigenvalues, eigenvectors = eigenvalues[sorted_indices], eigenvectors[:,sorted_indices]\n",
    "#     print(eigenvalues,'\\n'*2 ,eigenvectors)\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "def normalize_A_torch(a_m, d_m):\n",
    "    return torch.sqrt(torch.linalg.inv(d_m))@a_m@torch.sqrt(torch.linalg.inv(d_m))\n",
    "\n",
    "def dir_energy(data: torch.Tensor, sigma=1):\n",
    "    A, D, L = calc_D_L_torch(data, sigma=sigma)\n",
    "    eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "    energy = calc_energy_from_values(eigenvalues)\n",
    "    return energy\n",
    "\n",
    "def calc_energy_from_values(values: torch.Tensor):\n",
    "    nsamples = len(values)\n",
    "    max_value = nsamples * (nsamples - 1)\n",
    "    dir_energy = values.sum()\n",
    "    energy_p = dir_energy / max_value\n",
    "    return energy_p.cpu().item()\n",
    "\n",
    "def dir_energy_normal(data: torch.Tensor):\n",
    "    A, D, L = calc_D_L_torch(data)\n",
    "    L_norm = torch.eye(A.shape[0]).to('cuda')-normalize_A_torch(A, D)\n",
    "    eigenvalues, eigenvectors = find_eig_torch(L_norm)\n",
    "    nsamples = len(data)\n",
    "    max_value = nsamples - 1\n",
    "    dir_energy = eigenvalues.sum()\n",
    "    energy_p = dir_energy / max_value\n",
    "    return energy_p.cpu().item()\n",
    "\n",
    "def flatten_list(l: List[List[any]]) -> List[any]:\n",
    "    return [item for line in l for item in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logs_path = 'C:\\\\Users\\\\emace\\\\AImageLab\\\\SRV-Continual\\\\results\\\\canomaly\\\\logs'\n",
    "logs_path = '../storage/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_dict = {}\n",
    "environments = []\n",
    "for log_file in glob(logs_path + '/**rec**/*.pyd', recursive=True):\n",
    "    print(log_file)\n",
    "    with open(log_file, 'r') as f:\n",
    "        props_list = [prop.split('-', 1) for prop in log_file.replace(logs_path, '').split('\\\\')[1:-1]]\n",
    "        props = {prop[0]: prop[1] for prop in props_list}\n",
    "        exps = []\n",
    "        for i, line in enumerate(f.readlines()):\n",
    "            try:\n",
    "                exps.append(literal_eval(line.replace('nan', 'None')))\n",
    "            except:\n",
    "                print(f'Unparsed line {i}:\\n\\t{exps[:-1]}\\n-->\\t{line}')\n",
    "\n",
    "        environments.append({'env': props, 'exps': exps})\n",
    "\n",
    "        exps = {exp['id']: exp for exp in exps}\n",
    "        exp_dict = {**exp_dict, **exps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "exp_list = environments[0]['exps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_exp_energies(exp: dict, index=0, sigma=1,):\n",
    "    print_exp_info(exp)\n",
    "    model = exp['model']\n",
    "    app = exp['approach']\n",
    "    name = model + ' ' + app + ' ' + str(index)\n",
    "#     sigma = 10 if exp['model'] != 'rec-vae'\n",
    "    exp_df = pd.DataFrame(columns=['current', 'past', 'total'])\n",
    "    exp_df.columns = pd.MultiIndex.from_product([[name], ['current', 'past', 'total']])\n",
    "    for task_id in exp['results']:\n",
    "        task_idx = int(task_id)\n",
    "        task = exp['results'][task_id]\n",
    "        targets = torch.tensor(task['targets'], device='cuda')\n",
    "        latents = torch.tensor(task['latents'], device='cuda')\n",
    "        knowledge = [k for k in exp['knowledge'].values()]\n",
    "        for i in range(1, len(knowledge)):\n",
    "            knowledge[i] = [k for k in knowledge[i] if k not in flatten_list(knowledge[:i])]\n",
    "\n",
    "        cur_latents = latents[np.isin(targets.cpu(), knowledge[task_idx])]\n",
    "        past_latents = latents[np.isin(targets.cpu(), flatten_list(knowledge[:task_idx+1]))]\n",
    "        fut_latents = latents[np.isin(targets.cpu(), flatten_list(knowledge[task_idx:]))]\n",
    "        \n",
    "        cur_energy = dir_energy(cur_latents, sigma)\n",
    "        past_energy = dir_energy(past_latents, sigma)\n",
    "        tot_energy = dir_energy(latents, sigma)\n",
    "        exp_df.loc[task_idx, (name, slice(None))] = cur_energy,past_energy,tot_energy\n",
    "        \n",
    "        print(f'{task_idx}. Task {task_id} ({knowledge[task_idx]})\\n'\n",
    "              f'current:        energy {cur_energy:.4f}     \\tmean {cur_latents.mean():.3f} ± {cur_latents.std():.3f}\\n'\n",
    "              f'with past:      energy {past_energy:.4f}    \\tmean {past_latents.mean():.3f} ± {past_latents.std():.3f}\\n'\n",
    "#               f'with future:    energy {dir_energy(fut_latents, sigma):.4f}     \\tmean {fut_latents.mean():.3f} ± {fut_latents.std():.3f}\\n'\n",
    "              f'total:          energy {tot_energy:.4f}      \\tmean {latents.mean():.3f} ± {latents.std():.3f}')\n",
    "    return exp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "experiments = [x for x in environments[0]['exps'] if 'rec-vae' in x['model'] \n",
    "#                and len(x['results'])>1 \n",
    "               and x['n_epochs']>1\n",
    "              and x['approach'] == 'joint'\n",
    "               and x['optim'] == 'adam'\n",
    "              ]\n",
    "total_list = []\n",
    "for num, exp in enumerate(experiments):    \n",
    "    print(f'--------------- {num} ---------------\\n')\n",
    "    exp_df = show_exp_energies(exp, num, sigma=1)\n",
    "    print('\\n-------------------------\\n')\n",
    "    total_list.append(exp_df)\n",
    "\n",
    "df_total = pd.concat(total_list, axis=1)\n",
    "\n",
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp = experiments[]\n",
    "sigma = 1\n",
    "print_exp_info(exp)\n",
    "figsize = (20, 7)\n",
    "limit = 100\n",
    "\n",
    "for task_id in exp['results']:\n",
    "    task_idx = int(task_id)\n",
    "    task = exp['results'][task_id]\n",
    "    targets = torch.tensor(task['targets'], device='cuda')\n",
    "    latents = torch.tensor(task['latents'], device='cuda')\n",
    "    knowledge = [k for k in exp['knowledge'].values()]\n",
    "    for i in range(1, len(knowledge)):\n",
    "        knowledge[i] = [k for k in knowledge[i] if k not in flatten_list(knowledge[:i])]\n",
    "\n",
    "    cur_latents = latents[np.isin(targets.cpu(), knowledge[task_idx])]\n",
    "    past_latents = latents[np.isin(targets.cpu(), flatten_list(knowledge[:task_idx+1]))]\n",
    "    fut_latents = latents[np.isin(targets.cpu(), flatten_list(knowledge[task_idx:]))]\n",
    "    past_targets = targets[np.isin(targets.cpu(), flatten_list(knowledge[:task_idx+1]))]\n",
    "    \n",
    "    \n",
    "    targets_knowledge = targets.clone()\n",
    "    for num, kn in enumerate(knowledge):\n",
    "        targets_knowledge[torch.isin(targets, torch.Tensor(kn).to('cuda'))] = num\n",
    "\n",
    "    fig, ax = plt.subplots(2, 3, figsize=figsize)\n",
    "    ax = np.array(ax).flatten().tolist()\n",
    "    A, D, L = calc_D_L_torch(cur_latents, sigma=sigma)\n",
    "    eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "    # eigenvalues /= len(cur_latents)\n",
    "    ax[0].plot(eigenvalues[1:limit].cpu(), '*')\n",
    "    ax[0].set_title(f'Current E={calc_energy_from_values(eigenvalues)}')\n",
    "\n",
    "    A, D, L = calc_D_L_torch(latents, sigma=sigma)\n",
    "    print((D.sum(1)-1).mean().item(),(D.sum(1)-1).std().item(), (D.sum(1)-1).min().item(), (D.sum(1)-1).max().item())\n",
    "    eigenvalues, eigenvectors = find_eig_torch(L)\n",
    "    # eigenvalues /= len(past_latents)\n",
    "    # ax[1].plot(eigenvalues[1:limit].cpu(), '*')\n",
    "    filt_1 = (np.quantile(eigenvectors[:, 1].cpu().numpy(), .99) > eigenvectors[:, 1].cpu().numpy()) & (eigenvectors[:, 1].cpu().numpy() > np.quantile(eigenvectors[:, 1].cpu().numpy(), .01))\n",
    "    filt_2 = (np.quantile(eigenvectors[:, 2].cpu().numpy(), .99) > eigenvectors[:, 2].cpu().numpy()) & (eigenvectors[:, 1].cpu().numpy() > np.quantile(eigenvectors[:, 2].cpu().numpy(), .01))\n",
    "    filt_total = filt_1 & filt_2\n",
    "#     ax[1].scatter(eigenvectors[filt_total, 1].cpu(), eigenvectors[filt_total, 2].cpu(), c=past_targets[filt_total].cpu())\n",
    "    ax[1].set_title(f'With Past E={calc_energy_from_values(eigenvalues)}')\n",
    "\n",
    "    ts = TSNE(n_components=2, random_state=0, perplexity=30)\n",
    "    tr = ts.fit_transform(eigenvectors[:,:11].cpu().numpy())\n",
    "#     ax[1].scatter(tr[:,0], tr[:,1], c=past_targets.cpu())\n",
    "    data = pd.DataFrame(np.concatenate([tr, targets_knowledge.cpu()[:, None]], axis=1), columns=['dim1','dim2','label'])\n",
    "    # fig,ax = plt.subplots(figsize=(10,10))\n",
    "    sns.scatterplot(x='dim1', y='dim2', hue='label', data=data, palette='tab10', ax=ax[1])\n",
    "\n",
    "    plt.suptitle(f'{task_idx}. Task {task_id} ({knowledge[task_idx]})')\n",
    "    ts = TSNE(n_components=2, perplexity=30, random_state=0)\n",
    "    tr = ts.fit_transform(latents.cpu().numpy())\n",
    "    data = pd.DataFrame(np.concatenate([tr, targets_knowledge.cpu()[:, None]], axis=1), columns=['dim1','dim2','label'])\n",
    "    # fig,ax = plt.subplots(figsize=(10,10))\n",
    "    sns.scatterplot(x='dim1', y='dim2', hue='label', data=data, palette='tab10', ax=ax[2])\n",
    "    \n",
    "    centroids = pd.DataFrame(np.concatenate([latents.cpu().numpy(), targets_knowledge.cpu().numpy()[:, None]],1),\n",
    "    columns=[i for i in range(latents.shape[1])]+['label']).groupby('label').agg([np.mean, np.std])\n",
    "    arr_centr = centroids.loc[:, (slice(None), 'mean')].values\n",
    "    dist_matrix = ((arr_centr[None, ...] - np.expand_dims(arr_centr, 1)) ** 2).sum(-1)\n",
    "    sns.heatmap(dist_matrix, annot=True, ax = ax[3])\n",
    "    sns.heatmap(centroids.loc[:, (slice(None), 'std')].mean(1).to_frame(),annot=True,ax=ax[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_exp_images(experiments[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_exp_images(experiments[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "useless_cols = ['seed', 'logs', 'timestamp']\n",
    "# cols without duplicates\n",
    "model_cols = {\n",
    "    'common_pre': ['n_epochs', 'batch_size', 'optim', 'lr', 'model'],\n",
    "    'ae': ['latent_space'],\n",
    "    'dae': ['noise_mean', 'noise_std'],\n",
    "    'sae': ['sparse_weight', 'norm_order'],\n",
    "    'vae': ['kl_weight', 'beta_kl', 'forward_sample'],\n",
    "    'common_post': ['approach', ['id']]\n",
    "}\n",
    "result_cols = ['results', 'knowledge']\n",
    "\n",
    "group_cols = [col for cols in model_cols for col in model_cols[cols]]\n",
    "order_cols = group_cols + result_cols\n",
    "\n",
    "methods_list = []\n",
    "def method_id(df: pd.DataFrame):\n",
    "    idx = len(methods_list)\n",
    "    methods_list.append({'exps': list(df)})\n",
    "    return idx\n",
    "\n",
    "for env in environments:\n",
    "    env_cols = [prop for prop in env['env']]\n",
    "\n",
    "    results = pd.DataFrame.from_records(env['exps'])\n",
    "    tot_cols = results.columns.tolist()\n",
    "    exclude_cols = [col for col in useless_cols + env_cols if col in tot_cols]\n",
    "    orderby_cols = [col for col in order_cols if col in tot_cols]\n",
    "    groupby_cols = [col for col in group_cols if col in tot_cols]\n",
    "    unknown_cols = [col for col in tot_cols if col not in exclude_cols + orderby_cols]\n",
    "    env['unknown'] = unknown_cols\n",
    "    results = results[orderby_cols]\n",
    "    results['runs'] = 1\n",
    "    results = results.groupby(groupby_cols, dropna=False).agg(\n",
    "        {'runs': 'count', 'id': method_id, **{res: ['mean', 'std'] for res in result_cols}}\n",
    "    )\n",
    "    for index, res in results.iterrows():\n",
    "        id_met = int(res[('id', 'method_id')])\n",
    "        methods_list[id_met]['props'] = {name: index[i] for i, name in enumerate(results.index.names)}\n",
    "        methods_list[id_met]['env'] = env['env']\n",
    "        methods_list[id_met]['results'] = {res_col: {'mean': res[(res_col, 'mean')], 'std': res[(res_col, 'std')]} for res_col in result_cols}\n",
    "\n",
    "    env['results'] = results\n",
    "\n",
    "sort = False\n",
    "sort_col = ('auc_final', 'mean')\n",
    "for env in environments:\n",
    "    print('ENV INFO - ' + str(env['env']))\n",
    "    if len(env['unknown']):\n",
    "        print('-- unknown props: ' + str(env['unknown']))\n",
    "    display(env['results'].sort_values(sort_col, ascending=False) if sort else env['results'])\n",
    "    print('-'*100 + '\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}